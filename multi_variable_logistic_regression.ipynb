{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-variable logistic regression\n",
    "# 1. 학습 데이터 준비\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([ [2,4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7] ])\n",
    "t_data = np.array([ [0, 0, 0, 0, 1, 1, 1, 1, 1]]).reshape(9, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.97297071]\n",
      " [0.25525686]] , W.shape = (2, 1) , b =  [0.22148941] , b.sahpe =  (1,)\n"
     ]
    }
   ],
   "source": [
    "# 2. 회귀선 정의 \n",
    "\n",
    "W = np.random.rand(2, 1) #2x1 행렬\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(\"W =\", W, \", W.shape =\", W.shape, \", b = \", b, \", b.sahpe = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 손실함수 E(W, b) 정의\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+ np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    delta = 1e-7 #log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    #cross-entropy\n",
    "    return -np.sum(t*np.log(y + delta) + (1-t)*np.log((1-y) + delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 수치미분 numerical_derivative 및 utility 함수 정의\n",
    "\n",
    "def numerical_derivative(f, x): #x는 모든 변수를 포함하고 있는 numpy객체(배열, 행렬...)\n",
    "    delta_x = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags=['readwrite']) #모든 입력변수에 대해 편미분하기 위해 iterator 사용\n",
    "    \n",
    "    while not it.finished: \n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx] \n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) #f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7 #log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    #cross-entropy\n",
    "    return -np.sum(t*np.log(y + delta) + (1-t)*np.log((1 - y) + delta))\n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y >= 0.5:\n",
    "        result = 1 #True\n",
    "    else:\n",
    "        result = 0 #False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error value = 27.022674741712716 initial W = [[0.97297071]\n",
      " [0.25525686]] \n",
      " , b = [0.22148941]\n",
      "step = 0 error value = 16.349331749824913 W = [[ 0.77394255]\n",
      " [-0.00293833]] , b =  [0.183421]\n",
      "step = 400 error value = 2.1919130677303977 W = [[ 0.43085577]\n",
      " [-0.08047676]] , b =  [-2.7823161]\n",
      "step = 800 error value = 1.559038848708326 W = [[ 0.54383879]\n",
      " [-0.02306623]] , b =  [-4.3623369]\n",
      "step = 1200 error value = 1.2625164565865052 W = [[0.62935271]\n",
      " [0.01123262]] , b =  [-5.44774219]\n",
      "step = 1600 error value = 1.0870323698305908 W = [[0.69866418]\n",
      " [0.03592469]] , b =  [-6.28354822]\n",
      "step = 2000 error value = 0.9687962903949066 W = [[0.75723649]\n",
      " [0.0557167 ]] , b =  [-6.96980004]\n",
      "step = 2400 error value = 0.8823150088088615 W = [[0.8081109 ]\n",
      " [0.07272738]] , b =  [-7.55674232]\n",
      "step = 2800 error value = 0.815401484544695 W = [[0.85315709]\n",
      " [0.08806203]] , b =  [-8.07302217]\n",
      "step = 3200 error value = 0.761482939623305 W = [[0.89361068]\n",
      " [0.10235371]] , b =  [-8.53644948]\n",
      "step = 3600 error value = 0.7166912361346367 W = [[0.93033464]\n",
      " [0.1159877 ]] , b =  [-8.95882041]\n",
      "step = 4000 error value = 0.678594057853131 W = [[0.96395886]\n",
      " [0.12920715]] , b =  [-9.34833632]\n",
      "step = 4400 error value = 0.6455803302102262 W = [[0.99496027]\n",
      " [0.14216769]] , b =  [-9.7109222]\n",
      "step = 4800 error value = 0.6165373396336586 W = [[1.02371142]\n",
      " [0.15496797]] , b =  [-10.05099347]\n",
      "step = 5200 error value = 0.590669715886098 W = [[1.05051119]\n",
      " [0.16766786]] , b =  [-10.37192582]\n",
      "step = 5600 error value = 0.567392393545913 W = [[1.07560492]\n",
      " [0.18030014]] , b =  [-10.67635586]\n",
      "step = 6000 error value = 0.546264433024523 W = [[1.09919779]\n",
      " [0.19287841]] , b =  [-10.96638056]\n",
      "step = 6400 error value = 0.5269465235967986 W = [[1.12146398]\n",
      " [0.20540293]] , b =  [-11.24369391]\n",
      "step = 6800 error value = 0.5091727894010798 W = [[1.14255301]\n",
      " [0.21786491]] , b =  [-11.50968304]\n",
      "step = 7200 error value = 0.4927315477822417 W = [[1.16259428]\n",
      " [0.23024989]] , b =  [-11.76549751]\n",
      "step = 7600 error value = 0.47745184941806734 W = [[1.18170027]\n",
      " [0.24254038]] , b =  [-12.01210035]\n",
      "step = 8000 error value = 0.46319385780182176 W = [[1.19996904]\n",
      " [0.25471785]] , b =  [-12.25030629]\n",
      "step = 8400 error value = 0.44984184216481365 W = [[1.21748615]\n",
      " [0.26676415]] , b =  [-12.48081091]\n",
      "step = 8800 error value = 0.43729898906615333 W = [[1.23432628]\n",
      " [0.27866256]] , b =  [-12.70421313]\n",
      "step = 9200 error value = 0.42548350461212414 W = [[1.25055454]\n",
      " [0.29039838]] , b =  [-12.92103275]\n",
      "step = 9600 error value = 0.4143256485436125 W = [[1.26622772]\n",
      " [0.30195927]] , b =  [-13.13172435]\n",
      "step = 10000 error value = 0.40376545143248826 W = [[1.2813953 ]\n",
      " [0.31333536]] , b =  [-13.33668833]\n",
      "step = 10400 error value = 0.3937509393213255 W = [[1.2961004 ]\n",
      " [0.32451916]] , b =  [-13.53627971]\n",
      "step = 10800 error value = 0.3842367397336322 W = [[1.31038069]\n",
      " [0.33550542]] , b =  [-13.73081528]\n",
      "step = 11200 error value = 0.37518297728033106 W = [[1.32426903]\n",
      " [0.34629088]] , b =  [-13.92057941]\n",
      "step = 11600 error value = 0.366554391227043 W = [[1.33779425]\n",
      " [0.35687403]] , b =  [-14.10582878]\n",
      "step = 12000 error value = 0.35831962463746697 W = [[1.35098164]\n",
      " [0.36725482]] , b =  [-14.28679626]\n",
      "step = 12400 error value = 0.3504506472040353 W = [[1.3638535 ]\n",
      " [0.37743444]] , b =  [-14.46369412]\n",
      "step = 12800 error value = 0.34292228303349126 W = [[1.37642956]\n",
      " [0.38741506]] , b =  [-14.63671672]\n",
      "step = 13200 error value = 0.3357118214308105 W = [[1.38872732]\n",
      " [0.39719966]] , b =  [-14.80604272]\n",
      "step = 13600 error value = 0.3287986937851159 W = [[1.40076243]\n",
      " [0.40679182]] , b =  [-14.97183697]\n",
      "step = 14000 error value = 0.3221642034658672 W = [[1.4125489 ]\n",
      " [0.41619559]] , b =  [-15.13425208]\n",
      "step = 14400 error value = 0.31579129852075716 W = [[1.42409934]\n",
      " [0.42541534]] , b =  [-15.2934298]\n",
      "step = 14800 error value = 0.30966437916425354 W = [[1.43542516]\n",
      " [0.43445569]] , b =  [-15.44950213]\n",
      "step = 15200 error value = 0.30376913373091385 W = [[1.44653673]\n",
      " [0.4433214 ]] , b =  [-15.60259232]\n",
      "step = 15600 error value = 0.2980923980678521 W = [[1.45744354]\n",
      " [0.4520173 ]] , b =  [-15.75281575]\n",
      "step = 16000 error value = 0.2926220343489311 W = [[1.46815425]\n",
      " [0.46054823]] , b =  [-15.90028064]\n",
      "step = 16400 error value = 0.2873468260800644 W = [[1.47867686]\n",
      " [0.46891904]] , b =  [-16.04508873]\n",
      "step = 16800 error value = 0.2822563866822475 W = [[1.48901874]\n",
      " [0.47713448]] , b =  [-16.18733582]\n",
      "step = 17200 error value = 0.27734107952545173 W = [[1.49918676]\n",
      " [0.48519925]] , b =  [-16.32711229]\n",
      "step = 17600 error value = 0.2725919476728536 W = [[1.50918728]\n",
      " [0.49311794]] , b =  [-16.46450353]\n",
      "step = 18000 error value = 0.2680006519023858 W = [[1.51902624]\n",
      " [0.50089501]] , b =  [-16.59959035]\n",
      "step = 18400 error value = 0.2635594158198268 W = [[1.52870923]\n",
      " [0.50853481]] , b =  [-16.73244931]\n",
      "step = 18800 error value = 0.2592609770762062 W = [[1.53824146]\n",
      " [0.51604156]] , b =  [-16.86315308]\n",
      "step = 19200 error value = 0.2550985438641796 W = [[1.54762785]\n",
      " [0.52341932]] , b =  [-16.99177066]\n",
      "step = 19600 error value = 0.25106575599857844 W = [[1.55687306]\n",
      " [0.53067203]] , b =  [-17.11836769]\n",
      "step = 20000 error value = 0.24715664999498252 W = [[1.56598146]\n",
      " [0.5378035 ]] , b =  [-17.24300665]\n",
      "step = 20400 error value = 0.24336562764778122 W = [[1.57495721]\n",
      " [0.54481739]] , b =  [-17.36574711]\n",
      "step = 20800 error value = 0.23968742768325182 W = [[1.58380426]\n",
      " [0.55171722]] , b =  [-17.48664586]\n",
      "step = 21200 error value = 0.23611710012354536 W = [[1.59252636]\n",
      " [0.5585064 ]] , b =  [-17.60575714]\n",
      "step = 21600 error value = 0.23264998304862836 W = [[1.60112706]\n",
      " [0.56518818]] , b =  [-17.72313279]\n",
      "step = 22000 error value = 0.22928168148598693 W = [[1.60960978]\n",
      " [0.57176572]] , b =  [-17.83882236]\n",
      "step = 22400 error value = 0.2260080481936209 W = [[1.61797776]\n",
      " [0.57824204]] , b =  [-17.95287329]\n",
      "step = 22800 error value = 0.22282516613255826 W = [[1.62623411]\n",
      " [0.58462005]] , b =  [-18.06533103]\n",
      "step = 23200 error value = 0.21972933245087536 W = [[1.63438179]\n",
      " [0.59090254]] , b =  [-18.17623911]\n",
      "step = 23600 error value = 0.2167170438232893 W = [[1.64242364]\n",
      " [0.59709221]] , b =  [-18.28563931]\n",
      "step = 24000 error value = 0.21378498300936113 W = [[1.65036241]\n",
      " [0.60319165]] , b =  [-18.39357172]\n",
      "step = 24400 error value = 0.21093000650970528 W = [[1.65820069]\n",
      " [0.60920333]] , b =  [-18.50007484]\n",
      "step = 24800 error value = 0.20814913321335643 W = [[1.66594101]\n",
      " [0.61512966]] , b =  [-18.60518565]\n",
      "step = 25200 error value = 0.20543953394190914 W = [[1.67358577]\n",
      " [0.62097293]] , b =  [-18.70893972]\n",
      "step = 25600 error value = 0.20279852180635285 W = [[1.68113731]\n",
      " [0.62673537]] , b =  [-18.81137127]\n",
      "step = 26000 error value = 0.20022354330190698 W = [[1.68859785]\n",
      " [0.63241912]] , b =  [-18.91251323]\n",
      "step = 26400 error value = 0.19771217007401123 W = [[1.69596956]\n",
      " [0.63802621]] , b =  [-19.01239732]\n",
      "step = 26800 error value = 0.19526209129584707 W = [[1.70325451]\n",
      " [0.64355865]] , b =  [-19.11105409]\n",
      "step = 27200 error value = 0.19287110660386186 W = [[1.71045471]\n",
      " [0.64901832]] , b =  [-19.20851299]\n",
      "step = 27600 error value = 0.19053711954300803 W = [[1.71757207]\n",
      " [0.65440708]] , b =  [-19.30480243]\n",
      "step = 28000 error value = 0.18825813147878864 W = [[1.72460848]\n",
      " [0.65972668]] , b =  [-19.39994982]\n",
      "step = 28400 error value = 0.18603223593681265 W = [[1.73156573]\n",
      " [0.66497885]] , b =  [-19.49398162]\n",
      "step = 28800 error value = 0.18385761333464792 W = [[1.73844556]\n",
      " [0.67016522]] , b =  [-19.58692337]\n",
      "step = 29200 error value = 0.1817325260742563 W = [[1.74524966]\n",
      " [0.6752874 ]] , b =  [-19.67879976]\n",
      "step = 29600 error value = 0.17965531396594484 W = [[1.75197966]\n",
      " [0.68034691]] , b =  [-19.76963464]\n",
      "step = 30000 error value = 0.17762438995774527 W = [[1.75863714]\n",
      " [0.68534523]] , b =  [-19.85945107]\n",
      "step = 30400 error value = 0.17563823614631968 W = [[1.76522361]\n",
      " [0.69028381]] , b =  [-19.94827137]\n",
      "step = 30800 error value = 0.17369540004774822 W = [[1.77174057]\n",
      " [0.69516401]] , b =  [-20.03611711]\n",
      "step = 31200 error value = 0.1717944911083969 W = [[1.77818943]\n",
      " [0.69998719]] , b =  [-20.1230092]\n",
      "step = 31600 error value = 0.16993417743791533 W = [[1.7845716 ]\n",
      " [0.70475463]] , b =  [-20.20896787]\n",
      "step = 32000 error value = 0.16811318274778164 W = [[1.79088842]\n",
      " [0.70946758]] , b =  [-20.29401271]\n",
      "step = 32400 error value = 0.16633028348037251 W = [[1.79714119]\n",
      " [0.71412725]] , b =  [-20.3781627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 32800 error value = 0.16458430611476504 W = [[1.80333118]\n",
      " [0.71873482]] , b =  [-20.46143627]\n",
      "step = 33200 error value = 0.16287412463656542 W = [[1.80945962]\n",
      " [0.72329141]] , b =  [-20.54385125]\n",
      "step = 33600 error value = 0.16119865816020473 W = [[1.8155277 ]\n",
      " [0.72779812]] , b =  [-20.62542496]\n",
      "step = 34000 error value = 0.1595568686929423 W = [[1.82153659]\n",
      " [0.73225602]] , b =  [-20.70617418]\n",
      "step = 34400 error value = 0.15794775903083763 W = [[1.82748741]\n",
      " [0.73666613]] , b =  [-20.78611522]\n",
      "step = 34800 error value = 0.15637037077754784 W = [[1.83338126]\n",
      " [0.74102945]] , b =  [-20.8652639]\n",
      "step = 35200 error value = 0.15482378247776554 W = [[1.8392192 ]\n",
      " [0.74534696]] , b =  [-20.94363558]\n",
      "step = 35600 error value = 0.15330710785741494 W = [[1.84500227]\n",
      " [0.74961958]] , b =  [-21.02124518]\n",
      "step = 36000 error value = 0.15181949416364443 W = [[1.85073147]\n",
      " [0.75384823]] , b =  [-21.09810722]\n",
      "step = 36400 error value = 0.15036012059805298 W = [[1.85640778]\n",
      " [0.75803379]] , b =  [-21.17423578]\n",
      "step = 36800 error value = 0.14892819683694097 W = [[1.86203216]\n",
      " [0.76217712]] , b =  [-21.24964456]\n",
      "step = 37200 error value = 0.14752296163317594 W = [[1.86760553]\n",
      " [0.76627905]] , b =  [-21.32434688]\n",
      "step = 37600 error value = 0.14614368149427237 W = [[1.8731288 ]\n",
      " [0.77034039]] , b =  [-21.39835571]\n",
      "step = 38000 error value = 0.1447896494319493 W = [[1.87860285]\n",
      " [0.77436192]] , b =  [-21.47168365]\n",
      "step = 38400 error value = 0.14346018377875894 W = [[1.88402853]\n",
      " [0.77834441]] , b =  [-21.54434297]\n",
      "step = 38800 error value = 0.14215462706742896 W = [[1.88940668]\n",
      " [0.78228859]] , b =  [-21.61634562]\n",
      "step = 39200 error value = 0.14087234496926715 W = [[1.89473811]\n",
      " [0.7861952 ]] , b =  [-21.68770321]\n",
      "step = 39600 error value = 0.13961272528787372 W = [[1.90002362]\n",
      " [0.79006492]] , b =  [-21.75842707]\n",
      "step = 40000 error value = 0.13837517700489563 W = [[1.90526397]\n",
      " [0.79389844]] , b =  [-21.82852823]\n",
      "step = 40400 error value = 0.13715912937471997 W = [[1.91045993]\n",
      " [0.79769642]] , b =  [-21.89801744]\n",
      "step = 40800 error value = 0.13596403106513752 W = [[1.91561222]\n",
      " [0.80145951]] , b =  [-21.96690517]\n",
      "step = 41200 error value = 0.13478934934132084 W = [[1.92072157]\n",
      " [0.80518833]] , b =  [-22.03520162]\n",
      "step = 41600 error value = 0.13363456929054623 W = [[1.92578867]\n",
      " [0.8088835 ]] , b =  [-22.10291675]\n",
      "step = 42000 error value = 0.13249919308536945 W = [[1.93081421]\n",
      " [0.81254561]] , b =  [-22.17006025]\n",
      "step = 42400 error value = 0.13138273928299238 W = [[1.93579886]\n",
      " [0.81617524]] , b =  [-22.2366416]\n",
      "step = 42800 error value = 0.13028474215880104 W = [[1.94074326]\n",
      " [0.81977295]] , b =  [-22.30267001]\n",
      "step = 43200 error value = 0.12920475107206775 W = [[1.94564805]\n",
      " [0.8233393 ]] , b =  [-22.36815451]\n",
      "step = 43600 error value = 0.12814232986214288 W = [[1.95051386]\n",
      " [0.82687482]] , b =  [-22.43310389]\n",
      "step = 44000 error value = 0.12709705627330184 W = [[1.95534128]\n",
      " [0.83038004]] , b =  [-22.49752671]\n",
      "step = 44400 error value = 0.12606852140682923 W = [[1.96013092]\n",
      " [0.83385545]] , b =  [-22.56143137]\n",
      "step = 44800 error value = 0.12505632919871942 W = [[1.96488335]\n",
      " [0.83730157]] , b =  [-22.62482604]\n",
      "step = 45200 error value = 0.1240600959216296 W = [[1.96959913]\n",
      " [0.84071887]] , b =  [-22.68771871]\n",
      "step = 45600 error value = 0.12307944970984964 W = [[1.97427883]\n",
      " [0.84410783]] , b =  [-22.75011718]\n",
      "step = 46000 error value = 0.12211403010596208 W = [[1.97892297]\n",
      " [0.84746891]] , b =  [-22.81202909]\n",
      "step = 46400 error value = 0.12116348762817289 W = [[1.9835321 ]\n",
      " [0.85080256]] , b =  [-22.87346188]\n",
      "step = 46800 error value = 0.12022748335705577 W = [[1.98810673]\n",
      " [0.85410921]] , b =  [-22.93442283]\n",
      "step = 47200 error value = 0.11930568854085968 W = [[1.99264736]\n",
      " [0.85738931]] , b =  [-22.99491906]\n",
      "step = 47600 error value = 0.11839778421830506 W = [[1.99715448]\n",
      " [0.86064326]] , b =  [-23.05495754]\n",
      "step = 48000 error value = 0.11750346085804723 W = [[2.0016286 ]\n",
      " [0.86387147]] , b =  [-23.11454506]\n",
      "step = 48400 error value = 0.11662241801390508 W = [[2.00607017]\n",
      " [0.86707435]] , b =  [-23.17368828]\n",
      "step = 48800 error value = 0.11575436399505352 W = [[2.01047966]\n",
      " [0.87025229]] , b =  [-23.23239372]\n",
      "step = 49200 error value = 0.11489901555049822 W = [[2.01485753]\n",
      " [0.87340566]] , b =  [-23.29066774]\n",
      "step = 49600 error value = 0.11405609756701181 W = [[2.01920422]\n",
      " [0.87653485]] , b =  [-23.34851658]\n",
      "step = 50000 error value = 0.11322534277999745 W = [[2.02352016]\n",
      " [0.87964021]] , b =  [-23.40594633]\n",
      "step = 50400 error value = 0.11240649149646041 W = [[2.02780579]\n",
      " [0.88272211]] , b =  [-23.46296296]\n",
      "step = 50800 error value = 0.11159929132970414 W = [[2.03206152]\n",
      " [0.88578088]] , b =  [-23.51957232]\n",
      "step = 51200 error value = 0.11080349694501475 W = [[2.03628777]\n",
      " [0.88881688]] , b =  [-23.57578012]\n",
      "step = 51600 error value = 0.11001886981591355 W = [[2.04048492]\n",
      " [0.89183043]] , b =  [-23.63159198]\n",
      "step = 52000 error value = 0.10924517799038895 W = [[2.04465338]\n",
      " [0.89482187]] , b =  [-23.68701337]\n",
      "step = 52400 error value = 0.10848219586669604 W = [[2.04879353]\n",
      " [0.8977915 ]] , b =  [-23.74204967]\n",
      "step = 52800 error value = 0.10772970397824282 W = [[2.05290575]\n",
      " [0.90073965]] , b =  [-23.79670615]\n",
      "step = 53200 error value = 0.10698748878712296 W = [[2.0569904 ]\n",
      " [0.90366662]] , b =  [-23.85098795]\n",
      "step = 53600 error value = 0.10625534248597111 W = [[2.06104786]\n",
      " [0.90657271]] , b =  [-23.90490015]\n",
      "step = 54000 error value = 0.10553306280760123 W = [[2.06507847]\n",
      " [0.90945821]] , b =  [-23.95844769]\n",
      "step = 54400 error value = 0.10482045284224291 W = [[2.06908259]\n",
      " [0.91232341]] , b =  [-24.01163542]\n",
      "step = 54800 error value = 0.10411732086190384 W = [[2.07306055]\n",
      " [0.91516858]] , b =  [-24.0644681]\n",
      "step = 55200 error value = 0.10342348015161079 W = [[2.0770127 ]\n",
      " [0.91799402]] , b =  [-24.1169504]\n",
      "step = 55600 error value = 0.10273874884715825 W = [[2.08093936]\n",
      " [0.92079998]] , b =  [-24.1690869]\n",
      "step = 56000 error value = 0.10206294977912769 W = [[2.08484086]\n",
      " [0.92358673]] , b =  [-24.22088208]\n",
      "step = 56400 error value = 0.10139591032284467 W = [[2.08871751]\n",
      " [0.92635452]] , b =  [-24.27234035]\n",
      "step = 56800 error value = 0.10073746225408364 W = [[2.09256962]\n",
      " [0.92910362]] , b =  [-24.32346601]\n",
      "step = 57200 error value = 0.10008744161018866 W = [[2.09639751]\n",
      " [0.93183427]] , b =  [-24.3742633]\n",
      "step = 57600 error value = 0.09944568855640021 W = [[2.10020146]\n",
      " [0.93454672]] , b =  [-24.42473638]\n",
      "step = 58000 error value = 0.09881204725719996 W = [[2.10398177]\n",
      " [0.9372412 ]] , b =  [-24.47488932]\n",
      "step = 58400 error value = 0.09818636575239523 W = [[2.10773874]\n",
      " [0.93991794]] , b =  [-24.52472613]\n",
      "step = 58800 error value = 0.09756849583781911 W = [[2.11147265]\n",
      " [0.94257719]] , b =  [-24.57425073]\n",
      "step = 59200 error value = 0.09695829295033297 W = [[2.11518376]\n",
      " [0.94521916]] , b =  [-24.62346697]\n",
      "step = 59600 error value = 0.09635561605707825 W = [[2.11887237]\n",
      " [0.94784407]] , b =  [-24.67237864]\n",
      "step = 60000 error value = 0.09576032754869364 W = [[2.12253874]\n",
      " [0.95045215]] , b =  [-24.72098945]\n",
      "step = 60400 error value = 0.0951722931364063 W = [[2.12618312]\n",
      " [0.9530436 ]] , b =  [-24.76930306]\n",
      "step = 60800 error value = 0.09459138175277951 W = [[2.12980579]\n",
      " [0.95561863]] , b =  [-24.81732304]\n",
      "step = 61200 error value = 0.0940174654560191 W = [[2.13340699]\n",
      " [0.95817745]] , b =  [-24.86505291]\n",
      "step = 61600 error value = 0.09345041933764597 W = [[2.13698697]\n",
      " [0.96072027]] , b =  [-24.91249613]\n",
      "step = 62000 error value = 0.0928901214333745 W = [[2.14054599]\n",
      " [0.96324727]] , b =  [-24.95965608]\n",
      "step = 62400 error value = 0.09233645263720312 W = [[2.14408428]\n",
      " [0.96575865]] , b =  [-25.00653612]\n",
      "step = 62800 error value = 0.09178929661838245 W = [[2.14760208]\n",
      " [0.9682546 ]] , b =  [-25.05313951]\n",
      "step = 63200 error value = 0.09124853974133855 W = [[2.15109963]\n",
      " [0.97073531]] , b =  [-25.09946947]\n",
      "step = 63600 error value = 0.09071407098830574 W = [[2.15457715]\n",
      " [0.97320096]] , b =  [-25.14552917]\n",
      "step = 64000 error value = 0.09018578188458377 W = [[2.15803488]\n",
      " [0.97565174]] , b =  [-25.19132171]\n",
      "step = 64400 error value = 0.08966356642638186 W = [[2.16147302]\n",
      " [0.97808781]] , b =  [-25.23685016]\n",
      "step = 64800 error value = 0.08914732101107048 W = [[2.16489181]\n",
      " [0.98050936]] , b =  [-25.28211752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 65200 error value = 0.08863694436980116 W = [[2.16829145]\n",
      " [0.98291655]] , b =  [-25.32712675]\n",
      "step = 65600 error value = 0.08813233750232341 W = [[2.17167216]\n",
      " [0.98530955]] , b =  [-25.37188074]\n",
      "step = 66000 error value = 0.08763340361403753 W = [[2.17503415]\n",
      " [0.98768853]] , b =  [-25.41638235]\n",
      "step = 66400 error value = 0.08714004805508278 W = [[2.17837761]\n",
      " [0.99005365]] , b =  [-25.4606344]\n",
      "step = 66800 error value = 0.08665217826144546 W = [[2.18170276]\n",
      " [0.99240507]] , b =  [-25.50463964]\n",
      "step = 67200 error value = 0.0861697036979819 W = [[2.18500978]\n",
      " [0.99474294]] , b =  [-25.5484008]\n",
      "step = 67600 error value = 0.08569253580330037 W = [[2.18829888]\n",
      " [0.99706742]] , b =  [-25.59192054]\n",
      "step = 68000 error value = 0.08522058793641468 W = [[2.19157024]\n",
      " [0.99937866]] , b =  [-25.63520149]\n",
      "step = 68400 error value = 0.08475377532514937 W = [[2.19482406]\n",
      " [1.00167681]] , b =  [-25.67824625]\n",
      "step = 68800 error value = 0.0842920150161607 W = [[2.19806051]\n",
      " [1.00396202]] , b =  [-25.72105735]\n",
      "step = 69200 error value = 0.08383522582656208 W = [[2.20127979]\n",
      " [1.00623443]] , b =  [-25.7636373]\n",
      "step = 69600 error value = 0.08338332829705924 W = [[2.20448207]\n",
      " [1.00849417]] , b =  [-25.80598857]\n",
      "step = 70000 error value = 0.08293624464662107 W = [[2.20766753]\n",
      " [1.0107414 ]] , b =  [-25.84811358]\n",
      "step = 70400 error value = 0.0824938987284951 W = [[2.21083634]\n",
      " [1.01297625]] , b =  [-25.89001471]\n",
      "step = 70800 error value = 0.08205621598765976 W = [[2.21398867]\n",
      " [1.01519885]] , b =  [-25.93169432]\n",
      "step = 71200 error value = 0.08162312341954919 W = [[2.2171247 ]\n",
      " [1.01740933]] , b =  [-25.97315473]\n",
      "step = 71600 error value = 0.0811945495300949 W = [[2.22024459]\n",
      " [1.01960782]] , b =  [-26.0143982]\n",
      "step = 72000 error value = 0.08077042429695099 W = [[2.22334851]\n",
      " [1.02179446]] , b =  [-26.05542698]\n",
      "step = 72400 error value = 0.08035067913194366 W = [[2.22643661]\n",
      " [1.02396937]] , b =  [-26.09624328]\n",
      "step = 72800 error value = 0.0799352468446215 W = [[2.22950905]\n",
      " [1.02613268]] , b =  [-26.13684927]\n",
      "step = 73200 error value = 0.07952406160696869 W = [[2.232566 ]\n",
      " [1.0282845]] , b =  [-26.1772471]\n",
      "step = 73600 error value = 0.07911705891909757 W = [[2.2356076 ]\n",
      " [1.03042496]] , b =  [-26.21743887]\n",
      "step = 74000 error value = 0.07871417557605048 W = [[2.23863401]\n",
      " [1.03255417]] , b =  [-26.25742665]\n",
      "step = 74400 error value = 0.07831534963554657 W = [[2.24164538]\n",
      " [1.03467225]] , b =  [-26.29721251]\n",
      "step = 74800 error value = 0.07792052038668591 W = [[2.24464185]\n",
      " [1.03677932]] , b =  [-26.33679844]\n",
      "step = 75200 error value = 0.07752962831958948 W = [[2.24762358]\n",
      " [1.03887549]] , b =  [-26.37618644]\n",
      "step = 75600 error value = 0.07714261509594109 W = [[2.2505907 ]\n",
      " [1.04096088]] , b =  [-26.41537847]\n",
      "step = 76000 error value = 0.0767594235203566 W = [[2.25354335]\n",
      " [1.04303558]] , b =  [-26.45437644]\n",
      "step = 76400 error value = 0.0763799975126206 W = [[2.25648168]\n",
      " [1.04509971]] , b =  [-26.49318227]\n",
      "step = 76800 error value = 0.07600428208070655 W = [[2.25940582]\n",
      " [1.04715338]] , b =  [-26.53179781]\n",
      "step = 77200 error value = 0.0756322232945958 W = [[2.26231591]\n",
      " [1.04919669]] , b =  [-26.57022492]\n",
      "step = 77600 error value = 0.07526376826081087 W = [[2.26521208]\n",
      " [1.05122974]] , b =  [-26.60846542]\n",
      "step = 78000 error value = 0.07489886509770084 W = [[2.26809446]\n",
      " [1.05325264]] , b =  [-26.64652109]\n",
      "step = 78400 error value = 0.07453746291145456 W = [[2.27096319]\n",
      " [1.05526548]] , b =  [-26.68439371]\n",
      "step = 78800 error value = 0.07417951177273084 W = [[2.27381838]\n",
      " [1.05726837]] , b =  [-26.72208501]\n",
      "step = 79200 error value = 0.07382496269399519 W = [[2.27666017]\n",
      " [1.0592614 ]] , b =  [-26.75959671]\n",
      "step = 79600 error value = 0.07347376760747408 W = [[2.27948868]\n",
      " [1.06124467]] , b =  [-26.7969305]\n",
      "step = 80000 error value = 0.0731258793437287 W = [[2.28230404]\n",
      " [1.06321827]] , b =  [-26.83408806]\n"
     ]
    }
   ],
   "source": [
    "# 5. 학습율(learning rate) 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트\n",
    "\n",
    "learning_rate = 1e-2 #발산하는 경우, 1e-3 ~ 1e-6 등으로 바꿔 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data) # f(x) = loss_func(x_data, t_data)\n",
    "\n",
    "print(\"initial error value =\", error_val(x_data, t_data), \"initial W =\", W, \"\\n\", \", b =\", b)\n",
    "\n",
    "for step in range(80001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step =\", step, \"error value =\", error_val(x_data, t_data), \"W =\", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step = 80000 error value = 0.0731258793437287 W ## = [[2.28230404] [1.06321827]] , b =  [-26.83408806]\n",
    "## W1 = 2.28 / W2 = 1.06인 것으로 보아 예습이 학습 결과에 W2보다 큰 영향을 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.12870414]), 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([3, 17]) # (예습, 복습) = (3, 17) => Fail (0)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00098999]), 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([5, 8]) # (예습, 복습) = (5, 8) => Fail (0)\n",
    "\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99998956]), 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([7, 21]) # (예습, 복습) = (7, 21) => Fail (0)\n",
    "\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.63496124]), 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([12, 0]) # (예습, 복습) = (12, 0) => Fail (0)\n",
    "\n",
    "predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
